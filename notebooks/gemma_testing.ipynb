{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b91658d9-f825-4810-8bbf-8a4c656a6802",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to create LLM 'gemma2b' from 'D:/Varun PERSONAL/Edcite/smart_feedback_generator/models/gemma/Vikhr-Gemma-2B-instruct-Q4_K_M.gguf'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m model_path = \u001b[33m\"\u001b[39m\u001b[33mD:/Varun PERSONAL/Edcite/smart_feedback_generator/models/gemma/Vikhr-Gemma-2B-instruct-Q4_K_M.gguf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# âœ… 2. Load the model with correct type and settings\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m llm = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemma2b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Very important\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.1\u001b[39;49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# âœ… 3. Example test prompt\u001b[39;00m\n\u001b[32m     17\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33mWhat is photosynthesis?\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Varun PERSONAL\\Edcite\\smart_feedback_generator\\venv\\Lib\\site-packages\\ctransformers\\hub.py:175\u001b[39m, in \u001b[36mAutoModelForCausalLM.from_pretrained\u001b[39m\u001b[34m(cls, model_path_or_repo_id, model_type, model_file, config, lib, local_files_only, revision, hf, **kwargs)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m path_type == \u001b[33m\"\u001b[39m\u001b[33mrepo\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    168\u001b[39m     model_path = \u001b[38;5;28mcls\u001b[39m._find_model_path_from_repo(\n\u001b[32m    169\u001b[39m         model_path_or_repo_id,\n\u001b[32m    170\u001b[39m         model_file,\n\u001b[32m    171\u001b[39m         local_files_only=local_files_only,\n\u001b[32m    172\u001b[39m         revision=revision,\n\u001b[32m    173\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m llm = \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hf:\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Varun PERSONAL\\Edcite\\smart_feedback_generator\\venv\\Lib\\site-packages\\ctransformers\\llm.py:253\u001b[39m, in \u001b[36mLLM.__init__\u001b[39m\u001b[34m(self, model_path, model_type, config, lib)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28mself\u001b[39m._llm = \u001b[38;5;28mself\u001b[39m._lib.ctransformers_llm_create(\n\u001b[32m    248\u001b[39m     model_path.encode(),\n\u001b[32m    249\u001b[39m     model_type.encode(),\n\u001b[32m    250\u001b[39m     config.to_struct(),\n\u001b[32m    251\u001b[39m )\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._llm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    254\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to create LLM \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m from \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m     )\n\u001b[32m    256\u001b[39m architecture = \u001b[38;5;28mself\u001b[39m.ctransformers_llm_architecture().decode()\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m architecture:\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed to create LLM 'gemma2b' from 'D:/Varun PERSONAL/Edcite/smart_feedback_generator/models/gemma/Vikhr-Gemma-2B-instruct-Q4_K_M.gguf'."
     ]
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "# âœ… 1. Path to downloaded GGUF file\n",
    "model_path = \"D:/Varun PERSONAL/Edcite/smart_feedback_generator/models/gemma/Vikhr-Gemma-2B-instruct-Q4_K_M.gguf\"\n",
    "\n",
    "# âœ… 2. Load the model with correct type and settings\n",
    "llm = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    model_type=\"gemma2b\",  # Very important\n",
    "    max_new_tokens=150,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n",
    "# âœ… 3. Example test prompt\n",
    "question = \"What is photosynthesis?\"\n",
    "ideal_answer = \"Photosynthesis is the process by which plants use sunlight to convert carbon dioxide and water into glucose, producing oxygen as a byproduct.\"\n",
    "student_answer = \"Photosynthesis is when plants use the sun to make their own food.\"\n",
    "\n",
    "prompt = f\"\"\"You are a supportive but strict middle school science teacher.\n",
    "\n",
    "Question: {question}\n",
    "Ideal Answer: {ideal_answer}\n",
    "Student Answer: {student_answer}\n",
    "\n",
    "Your job is to give helpful, detailed feedback:\n",
    "- If the student answer is very similar to the ideal answer, say it is well-written or correct.\n",
    "- If they missed a key idea, give a gentle hint about what they could add â€” without giving away the keyword.\n",
    "- If there's a spelling mistake in an important word, gently point it out without saying the correct word.\n",
    "- Do not repeat the ideal answer.\n",
    "- Avoid saying â€œwrongâ€ â€” always be constructive.\n",
    "\n",
    "Start directly with feedback. Keep it natural and encouraging.\"\"\"\n",
    "\n",
    "# âœ… 4. Run inference\n",
    "response = llm(prompt)\n",
    "print(\"ðŸ“ Feedback:\\n\", response.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd147b13-7fee-4b98-8020-df5a401a156e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to create LLM 'gguf' from 'D:/Varun PERSONAL/Edcite/smart_feedback_generator/models/gemma/Vikhr-Gemma-2B-instruct-Q4_K_M.gguf'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m model_path = \u001b[33m\"\u001b[39m\u001b[33mD:/Varun PERSONAL/Edcite/smart_feedback_generator/models/gemma/Vikhr-Gemma-2B-instruct-Q4_K_M.gguf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Try with the correct model_type for ctransformers\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m llm = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No model_type specified, let it auto-detect\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.1\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Test the model\u001b[39;00m\n\u001b[32m     16\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33mWhat is photosynthesis?\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Varun PERSONAL\\Edcite\\smart_feedback_generator\\venv\\Lib\\site-packages\\ctransformers\\hub.py:175\u001b[39m, in \u001b[36mAutoModelForCausalLM.from_pretrained\u001b[39m\u001b[34m(cls, model_path_or_repo_id, model_type, model_file, config, lib, local_files_only, revision, hf, **kwargs)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m path_type == \u001b[33m\"\u001b[39m\u001b[33mrepo\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    168\u001b[39m     model_path = \u001b[38;5;28mcls\u001b[39m._find_model_path_from_repo(\n\u001b[32m    169\u001b[39m         model_path_or_repo_id,\n\u001b[32m    170\u001b[39m         model_file,\n\u001b[32m    171\u001b[39m         local_files_only=local_files_only,\n\u001b[32m    172\u001b[39m         revision=revision,\n\u001b[32m    173\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m llm = \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hf:\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Varun PERSONAL\\Edcite\\smart_feedback_generator\\venv\\Lib\\site-packages\\ctransformers\\llm.py:253\u001b[39m, in \u001b[36mLLM.__init__\u001b[39m\u001b[34m(self, model_path, model_type, config, lib)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28mself\u001b[39m._llm = \u001b[38;5;28mself\u001b[39m._lib.ctransformers_llm_create(\n\u001b[32m    248\u001b[39m     model_path.encode(),\n\u001b[32m    249\u001b[39m     model_type.encode(),\n\u001b[32m    250\u001b[39m     config.to_struct(),\n\u001b[32m    251\u001b[39m )\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._llm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    254\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to create LLM \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m from \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m     )\n\u001b[32m    256\u001b[39m architecture = \u001b[38;5;28mself\u001b[39m.ctransformers_llm_architecture().decode()\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m architecture:\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed to create LLM 'gguf' from 'D:/Varun PERSONAL/Edcite/smart_feedback_generator/models/gemma/Vikhr-Gemma-2B-instruct-Q4_K_M.gguf'."
     ]
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "model_path = \"D:/Varun PERSONAL/Edcite/smart_feedback_generator/models/gemma/Vikhr-Gemma-2B-instruct-Q4_K_M.gguf\"\n",
    "\n",
    "# Try with the correct model_type for ctransformers\n",
    "llm = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    # No model_type specified, let it auto-detect\n",
    "    max_new_tokens=150,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n",
    "# Test the model\n",
    "question = \"What is photosynthesis?\"\n",
    "print(llm(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91d0766-da0c-4e66-b646-bb92790ff753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
