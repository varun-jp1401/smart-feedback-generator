{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e80e4476-672b-47f6-96c5-955d201dabe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise: Give 5 minutes of feedback on a test. Choose students at random and ask them to write a short paragraph about a favorite vacation spot, using the prompts provided in the text material. Then, give detailed feedback on their writing, pointing out what they did well and what could be improved.\n",
      "\n",
      "Exercise: Give 5 minutes of feedback on a test. Choose students at random and ask them to write a short paragraph about an event or experience they\n"
     ]
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "# Load the TinyLlama model from local path\n",
    "model_path = \"D:/Varun PERSONAL/Edcite/smart_feedback_generator/models/tinyllama/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf\"\n",
    "\n",
    "llm = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    model_type=\"llama\",\n",
    "    max_new_tokens=100,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "# Test with a simple prompt\n",
    "prompt = \"\"\"\"You are a supportive but strict middle school science teacher.\n",
    "\n",
    "Question: What causes tides in the ocean?\n",
    "Ideal Answer: Tides are caused by the gravitational pull of the moon.\n",
    "Student Answer: The moon's pull causes tides.\n",
    "\n",
    "Your job is to give helpful, detailed feedback:\n",
    "- If the student answer is very similar to the ideal answer, say it is well-written or correct.\n",
    "- If they missed a key idea, give a gentle hint about what they could add ‚Äî without giving away the keyword.\n",
    "- If there's a spelling mistake in an important word, gently point it out without saying the correct word.\n",
    "- Do not repeat the ideal answer.\n",
    "- Avoid saying ‚Äúwrong‚Äù ‚Äî always be constructive.\n",
    "\n",
    "Start directly with feedback. Keep it natural and encouraging.\n",
    "\n",
    "\"\"\"\n",
    "response = llm(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2708362f-2124-4853-aa8b-212595061fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìò Processing Grade 5\n",
      "üîπ Generating feedback for: student_answer_close\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [01:50<00:00, 11.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Generating feedback for: student_answer_partial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [01:59<00:00, 11.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Generating feedback for: student_answer_wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [02:23<00:00, 14.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: D:/Varun PERSONAL/Edcite/smart_feedback_generator/feedback\\grade5_with_local_feedback.csv\n",
      "\n",
      "üìò Processing Grade 6\n",
      "üîπ Generating feedback for: student_answer_close\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [02:06<00:00, 12.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Generating feedback for: student_answer_partial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [02:21<00:00, 14.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Generating feedback for: student_answer_wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [02:07<00:00, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: D:/Varun PERSONAL/Edcite/smart_feedback_generator/feedback\\grade6_with_local_feedback.csv\n",
      "\n",
      "üìò Processing Grade 7\n",
      "üîπ Generating feedback for: student_answer_close\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [02:19<00:00, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Generating feedback for: student_answer_partial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [02:25<00:00, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Generating feedback for: student_answer_wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [02:23<00:00, 14.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: D:/Varun PERSONAL/Edcite/smart_feedback_generator/feedback\\grade7_with_local_feedback.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "# ‚úÖ Step 1: Load TinyLlama locally\n",
    "model_path = \"D:/Varun PERSONAL/Edcite/smart_feedback_generator/models/tinyllama/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf\"\n",
    "\n",
    "llm = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    model_type=\"llama\",\n",
    "    max_new_tokens=150,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "# ‚úÖ Step 2: Build subtle, helpful feedback prompt\n",
    "def build_prompt(question, ideal_answer, student_answer):\n",
    "    return f\"\"\"You are a supportive but strict middle school science teacher.\n",
    "\n",
    "Question: {question}\n",
    "Ideal Answer: {ideal_answer}\n",
    "Student Answer: {student_answer}\n",
    "\n",
    "Your job is to give helpful, detailed feedback:\n",
    "- If the student answer is very similar to the ideal answer, say it is well-written or correct.\n",
    "- If they missed a key idea, give a gentle hint about what they could add ‚Äî without giving away the keyword.\n",
    "- If there's a spelling mistake in an important word, gently point it out without saying the correct word.\n",
    "- Do not repeat the ideal answer.\n",
    "- Avoid saying ‚Äúwrong‚Äù ‚Äî always be constructive.\n",
    "\n",
    "Start directly with feedback. Keep it natural and encouraging.\"\"\"\n",
    "\n",
    "# ‚úÖ Step 3: Feedback generation logic\n",
    "def generate_feedback(prompt):\n",
    "    return llm(prompt).strip()\n",
    "\n",
    "# ‚úÖ Step 4: Run for all grades and answer types\n",
    "grades = [5, 6, 7]\n",
    "input_base = \"D:/Varun PERSONAL/Edcite/smart_feedback_generator/data\"\n",
    "output_base = \"D:/Varun PERSONAL/Edcite/smart_feedback_generator/feedback\"\n",
    "\n",
    "for grade in grades:\n",
    "    print(f\"\\nüìò Processing Grade {grade}\")\n",
    "    input_path = os.path.join(input_base, f\"grade{grade}.csv\")\n",
    "    output_path = os.path.join(output_base, f\"grade{grade}_with_local_feedback.csv\")\n",
    "\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"‚õî File not found: {input_path}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(input_path)\n",
    "\n",
    "    for label in ['close', 'partial', 'wrong']:\n",
    "        feedbacks = []\n",
    "        col_name = f\"student_answer_{label}\"\n",
    "        print(f\"üîπ Generating feedback for: {col_name}\")\n",
    "\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            question = str(row[\"question\"])\n",
    "            ideal = str(row[\"ideal_answer\"])\n",
    "            student = str(row[col_name])\n",
    "\n",
    "            prompt = build_prompt(question, ideal, student)\n",
    "\n",
    "            try:\n",
    "                feedback = generate_feedback(prompt)\n",
    "            except Exception as e:\n",
    "                feedback = f\"Error generating feedback: {e}\"\n",
    "\n",
    "            feedbacks.append(feedback)\n",
    "\n",
    "        df[f\"tinyllama_{label}_feedback\"] = feedbacks\n",
    "\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"‚úÖ Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63622a0a-5cd7-4d1d-8c80-292ed22e8619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
