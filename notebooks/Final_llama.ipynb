{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c89e10-b823-4dfe-babe-0366a15feedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Processing Grade 5\n",
      "🔹 Generating feedback for: student_answer_close\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:06<00:00, 12.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Generating feedback for: student_answer_partial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:16<00:00, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Generating feedback for: student_answer_wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:33<00:00, 15.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: D:/Varun PERSONAL/Edcite/smart_feedback_generator/feedback\\grade5_with_llama_feedback.csv\n",
      "\n",
      "📘 Processing Grade 6\n",
      "🔹 Generating feedback for: student_answer_close\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:18<00:00, 13.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Generating feedback for: student_answer_partial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:15<02:18, 15.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Other error: HTTPSConnectionPool(host='api.together.xyz', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B6014E3200>: Failed to resolve 'api.together.xyz' ([Errno 11001] getaddrinfo failed)\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [02:15<00:14, 14.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Other error: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n",
      "⚠️ Other error: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:32<00:00, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Generating feedback for: student_answer_wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:16<00:00, 13.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: D:/Varun PERSONAL/Edcite/smart_feedback_generator/feedback\\grade6_with_llama_feedback.csv\n",
      "\n",
      "📘 Processing Grade 7\n",
      "🔹 Generating feedback for: student_answer_close\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:20<00:00, 14.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Generating feedback for: student_answer_partial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:12<00:00, 13.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Generating feedback for: student_answer_wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:08<00:00, 12.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: D:/Varun PERSONAL/Edcite/smart_feedback_generator/feedback\\grade7_with_llama_feedback.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ API settings\n",
    "TOGETHER_API_URL = \"https://api.together.xyz/v1/chat/completions\"\n",
    "TOGETHER_API_KEY = \"92328edde95f65943128cf7ee4cef72431aaccd8de8cde7eef4c1195cad68a2e\"  # Replace this!\n",
    "\n",
    "MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\"  # You can change to another model\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOGETHER_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# ✅ System prompt (instructs model to behave like a teacher)\n",
    "SYSTEM_PROMPT = (\n",
    "    \"\"\"You are a supportive but strict middle school science teacher. \n",
    "Your job is to give smart, constructive feedback to a student's answer based on the question and the ideal answer.\n",
    "\n",
    "Rules:\n",
    "- if the answer is same as ideal answer, say its right.\n",
    "- If the student answer is very close to the ideal answer, acknowledge it positively.\n",
    "- If the student misses a key concept, give a gentle hint — do NOT directly mention the missing keyword.This is a very important point. Just give a hint and not the keyword directly\n",
    "- If there is a spelling mistake, only point it out if it's significant — but do NOT say the correct spelling. Be very careful when checking for spelling mistake.\n",
    "- Do NOT mention the ideal answer again.\n",
    "- Avoid saying 'wrong' or being negative. Be encouraging and helpful.\n",
    "- Keep feedback clear, natural, and student-facing — never include meta commentary or internal thoughts.\n",
    "\n",
    "Always start directly with the feedback.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# ✅ Prompt builder\n",
    "def build_prompt(question, ideal_answer, student_answer):\n",
    "    return (\n",
    "        f\"Question: {question}\\n\"\n",
    "        f\"Ideal Answer: {ideal_answer}\\n\"\n",
    "        f\"Student Answer: {student_answer}\\n\\n\"\n",
    "        f\"Now write helpful, encouraging feedback for the student.\"\n",
    "    )\n",
    "\n",
    "# ✅ Remove <think>...</think> blocks\n",
    "def clean_response(text):\n",
    "    return re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL).strip()\n",
    "\n",
    "# ✅ LLM call function with 15s delay and retry logic\n",
    "def generate_feedback(question, ideal, student):\n",
    "    prompt = build_prompt(question, ideal, student)\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"max_tokens\": 1500,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.9,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            response = requests.post(TOGETHER_API_URL, headers=HEADERS, json=payload, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            raw = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "            cleaned = clean_response(raw)\n",
    "            time.sleep(5)  # ⏲️ Wait 15 seconds after every call\n",
    "            return cleaned\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            print(f\"⚠️ HTTP error: {e}\")\n",
    "            time.sleep(5)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Other error: {e}\")\n",
    "            time.sleep(5)\n",
    "\n",
    "    return \"Error generating feedback\"\n",
    "\n",
    "# ✅ CSV Processing\n",
    "grades = [5, 6, 7]\n",
    "input_base = \"D:/Varun PERSONAL/Edcite/smart_feedback_generator/data\"\n",
    "output_base = \"D:/Varun PERSONAL/Edcite/smart_feedback_generator/feedback\"\n",
    "\n",
    "for grade in grades:\n",
    "    print(f\"\\n📘 Processing Grade {grade}\")\n",
    "    input_path = os.path.join(input_base, f\"grade{grade}.csv\")\n",
    "    output_path = os.path.join(output_base, f\"grade{grade}_with_llama_feedback.csv\")\n",
    "\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"⛔ File not found: {input_path}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(input_path)\n",
    "\n",
    "    for label in ['close', 'partial', 'wrong']:\n",
    "        feedbacks = []\n",
    "        col_name = f\"student_answer_{label}\"\n",
    "        print(f\"🔹 Generating feedback for: {col_name}\")\n",
    "\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            question = str(row[\"question\"])\n",
    "            ideal = str(row[\"ideal_answer\"])\n",
    "            student = str(row[col_name])\n",
    "            feedback = generate_feedback(question, ideal, student)\n",
    "            feedbacks.append(feedback)\n",
    "\n",
    "        df[f\"llama_{label}_feedback\"] = feedbacks\n",
    "\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✅ Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4002585-0b97-4e50-82ad-5aedddd68312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Grade 5\n",
      "Generating feedback for student_answer_close\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:47<01:08, 11.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Error: 429 Client Error: Too Many Requests for url: https://api.together.xyz/v1/chat/completions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:00<00:00, 12.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feedback for student_answer_partial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:20<01:21, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Error: 429 Client Error: Too Many Requests for url: https://api.together.xyz/v1/chat/completions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:07<00:00, 12.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feedback for student_answer_wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:48<00:00, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:/Varun PERSONAL/Edcite/smart_feedback_generator/feedback\\grade5_with_llama_feedback.csv\n",
      "\n",
      "Processing Grade 6\n",
      "Generating feedback for student_answer_close\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:01<00:00, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feedback for student_answer_partial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:00<00:00, 12.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feedback for student_answer_wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:59<00:58, 11.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Error: 429 Client Error: Too Many Requests for url: https://api.together.xyz/v1/chat/completions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:13<00:00, 13.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:/Varun PERSONAL/Edcite/smart_feedback_generator/feedback\\grade6_with_llama_feedback.csv\n",
      "\n",
      "Processing Grade 7\n",
      "Generating feedback for student_answer_close\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:09<01:26,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Error: 429 Client Error: Too Many Requests for url: https://api.together.xyz/v1/chat/completions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:59<00:00, 11.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feedback for student_answer_partial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [01:05<01:00, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Error: 429 Client Error: Too Many Requests for url: https://api.together.xyz/v1/chat/completions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:10<00:00, 13.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feedback for student_answer_wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:32<00:22, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Error: 429 Client Error: Too Many Requests for url: https://api.together.xyz/v1/chat/completions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:47<00:12, 12.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Error: 429 Client Error: Too Many Requests for url: https://api.together.xyz/v1/chat/completions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:10<00:00, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:/Varun PERSONAL/Edcite/smart_feedback_generator/feedback\\grade7_with_llama_feedback.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from keybert import KeyBERT\n",
    "\n",
    "# ✅ 1. Setup KeyBERT for keyword extraction\n",
    "kw_model = KeyBERT(model='all-MiniLM-L6-v2')\n",
    "\n",
    "# ✅ 2. Together API setup\n",
    "TOGETHER_API_URL = \"https://api.together.xyz/v1/chat/completions\"\n",
    "TOGETHER_API_KEY = \"92328edde95f65943128cf7ee4cef72431aaccd8de8cde7eef4c1195cad68a2e\"  # ← Replace this\n",
    "\n",
    "MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\"\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOGETHER_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# ✅ 3. Clean <think> tags\n",
    "def clean_response(text):\n",
    "    return re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL).strip()\n",
    "\n",
    "# ✅ 4. Extract keywords from the ideal answer\n",
    "def extract_keywords(text, top_k=5):\n",
    "    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words='english', top_n=top_k)\n",
    "    return [kw[0].lower() for kw in keywords]\n",
    "\n",
    "# ✅ 5. Check which keywords are missing in student answer\n",
    "def find_missing_keywords(keywords, student_answer):\n",
    "    student_answer = student_answer.lower()\n",
    "    missing = [kw for kw in keywords if kw not in student_answer]\n",
    "    return missing\n",
    "\n",
    "# ✅ 6. Build prompt with gentle hints\n",
    "def build_prompt(question, ideal_answer, student_answer, missing_keywords):\n",
    "    hint = \"\"\n",
    "    if missing_keywords:\n",
    "        hint = \"It seems the student may have missed one or more important scientific ideas. Consider gently prompting them to revisit key parts of the process.\"\n",
    "\n",
    "    return (\n",
    "        \n",
    "        f\"You are a supportive but strict middle school science teacher.\\n\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "        f\"Ideal Answer: {ideal_answer}\\n\"\n",
    "        f\"Student Answer: {student_answer}\\n\\n\"\n",
    "        f\"{hint}\\n\\n\"\n",
    "        f\"Now write helpful, constructive feedback for the student:\\n\"\n",
    "        f\"if the answer is same as or very close to the ideal answer, say its right.\\n\"\n",
    "        f\"- If their answer is close to the ideal answer, say it's good.\\n\"\n",
    "        f\"- If they missed something important, just hint at it — do not give the keyword.\\n\"\n",
    "        f\"- If there's a spelling mistake, suggest checking it without revealing it.Be very careful when checking for spelling mistake. Only alert if there is a spelling mistake,otherwise don't\\n\"\n",
    "        f\"- Do NOT mention the ideal answer.\\n\"\n",
    "        f\"- Do NOT include internal thoughts or use <think> tags.\\n\"\n",
    "        f\"- If the answer is completely wrong and not even close,dont be hesitant to tell it is wrong.\\n\"\n",
    "        f\"- Be friendly, clear, and encouraging.\"\n",
    "    )\n",
    "\n",
    "# ✅ 7. Generate feedback with retry and delay\n",
    "def generate_feedback(question, ideal, student):\n",
    "    keywords = extract_keywords(ideal)\n",
    "    missing = find_missing_keywords(keywords, student)\n",
    "    prompt = build_prompt(question, ideal, student, missing)\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"max_tokens\": 1500,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.9,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful science teacher.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            response = requests.post(TOGETHER_API_URL, headers=HEADERS, json=payload, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            raw = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "            feedback = clean_response(raw)\n",
    "            time.sleep(5)  # Respect rate limit\n",
    "            return feedback\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error: {e}\")\n",
    "            time.sleep(5)\n",
    "\n",
    "    return \"Error generating feedback.\"\n",
    "\n",
    "# ✅ 8. Run over CSVs for Grades 5–7\n",
    "grades = [5, 6, 7]\n",
    "input_base = \"D:/Varun PERSONAL/Edcite/smart_feedback_generator/data\"\n",
    "output_base = \"D:/Varun PERSONAL/Edcite/smart_feedback_generator/feedback\"\n",
    "\n",
    "for grade in grades:\n",
    "    print(f\"\\nProcessing Grade {grade}\")\n",
    "    input_path = os.path.join(input_base, f\"grade{grade}.csv\")\n",
    "    output_path = os.path.join(output_base, f\"grade{grade}_with_llama_feedback.csv\")\n",
    "\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"File not found: {input_path}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(input_path)\n",
    "\n",
    "    for label in ['close', 'partial', 'wrong']:\n",
    "        feedbacks = []\n",
    "        col = f\"student_answer_{label}\"\n",
    "        print(f\"Generating feedback for {col}\")\n",
    "\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            question = str(row[\"question\"])\n",
    "            ideal = str(row[\"ideal_answer\"])\n",
    "            student = str(row[col])\n",
    "            feedbacks.append(generate_feedback(question, ideal, student))\n",
    "\n",
    "        df[f\"llama_{label}_feedback\"] = feedbacks\n",
    "\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87868848-86b4-4815-84b0-685340aa1ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
